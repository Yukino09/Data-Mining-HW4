{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ee61337",
   "metadata": {},
   "source": [
    "# Problem 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5ac100ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "689c97ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/r7/3d0n0k757_b0w6vq1zy4xl3w0000gn/T/ipykernel_52028/3618255921.py:4: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(url, names=column_names, delim_whitespace=True, na_values='?')\n"
     ]
    }
   ],
   "source": [
    "#Load the auto-mpg dataset\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data'\n",
    "column_names = ['mpg', 'cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'model_year', 'origin', 'car_name']\n",
    "df = pd.read_csv(url, names=column_names, delim_whitespace=True, na_values='?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "56f7132f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select continuous fields as features\n",
    "continuous_features = ['mpg', 'displacement', 'horsepower', 'weight', 'acceleration']\n",
    "X = df[continuous_features]\n",
    "\n",
    "# Impute missing values with the mean\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_imputed = pd.DataFrame(imputer.fit_transform(X), columns=continuous_features)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X_imputed), columns=continuous_features)\n",
    "\n",
    "# Perform Hierarchical Clustering\n",
    "clustering = AgglomerativeClustering(n_clusters=3, linkage='average', metric='euclidean')\n",
    "cluster_labels = clustering.fit_predict(X_scaled)\n",
    "\n",
    "# Add cluster labels to the dataframe\n",
    "df['cluster'] = cluster_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6c44fa00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cluster Statistics (Mean and Variance):\n",
      "           mpg        displacement          horsepower           weight  \\\n",
      "          mean    var         mean      var       mean     var     mean   \n",
      "cluster                                                                   \n",
      "0        26.18  41.30       144.30  3511.49      86.12  294.55  2598.41   \n",
      "1        14.53   4.77       348.02  2089.50     161.80  674.08  4143.97   \n",
      "2        43.70   0.30        91.75    12.25      49.00    4.00  2133.75   \n",
      "\n",
      "                   acceleration        \n",
      "               var         mean   var  \n",
      "cluster                                \n",
      "0        299118.71        16.43  4.88  \n",
      "1        193847.05        12.64  3.19  \n",
      "2         21672.92        22.88  2.31  \n",
      "\n",
      "Origin Class Statistics (Mean and Variance):\n",
      "          mpg        displacement          horsepower            weight  \\\n",
      "         mean    var         mean      var       mean      var     mean   \n",
      "origin                                                                    \n",
      "1       20.08  41.00       245.90  9702.61     119.05  1591.83  3361.93   \n",
      "2       27.89  45.21       109.14   509.95      80.56   406.34  2423.30   \n",
      "3       30.45  37.09       102.71   535.47      79.84   317.52  2221.23   \n",
      "\n",
      "                  acceleration        \n",
      "              var         mean   var  \n",
      "origin                                \n",
      "1       631695.13        15.03  7.57  \n",
      "2       240142.33        16.79  9.28  \n",
      "3       102718.49        16.17  3.82  \n",
      "\n",
      "Contingency Table (Cluster vs. Origin):\n",
      "origin     1   2   3\n",
      "cluster             \n",
      "0        152  66  79\n",
      "1         97   0   0\n",
      "2          0   4   0\n"
     ]
    }
   ],
   "source": [
    "# Compute mean and variance for each cluster (on original scale for interpretability)\n",
    "cluster_stats = df.groupby('cluster')[continuous_features].agg(['mean', 'var']).round(2)\n",
    "print(\"\\nCluster Statistics (Mean and Variance):\")\n",
    "print(cluster_stats)\n",
    "\n",
    "# Compute mean and variance for each origin class\n",
    "origin_stats = df.groupby('origin')[continuous_features].agg(['mean', 'var']).round(2)\n",
    "print(\"\\nOrigin Class Statistics (Mean and Variance):\")\n",
    "print(origin_stats)\n",
    "\n",
    "# Analyze relationship between clusters and origin\n",
    "crosstab = pd.crosstab(df['cluster'], df['origin'])\n",
    "print(\"\\nContingency Table (Cluster vs. Origin):\")\n",
    "print(crosstab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c35bde",
   "metadata": {},
   "source": [
    "## Result\n",
    "\n",
    "There was no clear relationship between cluster assignment and source category labeling. While Cluster 1 corresponds exactly to American cars (Source 1) and Cluster 2 corresponds to a small fraction of European cars (Source 2), the largest cluster (Cluster 0, 74% of the data) mixes all sources (152 American, 66 European, and 79 Japanese cars) and does not allow for clear one-to-one mapping. This indicates that continuous features alone cannot fully distinguish between sources, especially European and Japanese cars."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c9391f",
   "metadata": {},
   "source": [
    "# Problem 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0e2d065c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cb64da67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1Load data and ensure numeric types\n",
    "boston = fetch_openml(name='boston', version=1, parser='auto')\n",
    "df = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
    "\n",
    "df = df.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Data standardization\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b862ec2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=2: Silhouette Score: 0.3601\n",
      "k=3: Silhouette Score: 0.2448\n",
      "k=4: Silhouette Score: 0.2275\n",
      "k=5: Silhouette Score: 0.2389\n",
      "k=6: Silhouette Score: 0.2291\n",
      "\n",
      "Optimal k value: 2\n"
     ]
    }
   ],
   "source": [
    "# Perform K-Means clustering analysis\n",
    "silhouette_scores = []\n",
    "for k in range(2, 7):\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    labels = kmeans.fit_predict(scaled_data)\n",
    "    score = silhouette_score(scaled_data, labels)\n",
    "    silhouette_scores.append(score)\n",
    "    print(f\"k={k}: Silhouette Score: {score:.4f}\")\n",
    "\n",
    "# Determine optimal k value\n",
    "best_k = range(2,7)[silhouette_scores.index(max(silhouette_scores))]\n",
    "print(f\"\\nOptimal k value: {best_k}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "594fc56f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Method 1: Cluster means from original data:\n",
      "       CRIM         ZN      INDUS      CHAS       NOX        RM        AGE  \\\n",
      "0  0.261172  17.477204   6.885046  0.069909  0.487011  6.455422  56.339210   \n",
      "1  9.844730   0.000000  19.039718  0.067797  0.680503  5.967181  91.318079   \n",
      "\n",
      "        DIS        RAD         TAX    PTRATIO           B      LSTAT  \n",
      "0  4.756868   4.471125  301.917933  17.837386  386.447872   9.468298  \n",
      "1  2.007242  18.988701  605.858757  19.604520  301.331695  18.572768  \n",
      "\n",
      "Method 2: Inverse-transformed centroids:\n",
      "       CRIM            ZN      INDUS      CHAS       NOX        RM        AGE  \\\n",
      "0  0.261172  1.747720e+01   6.885046  0.069909  0.487011  6.455422  56.339210   \n",
      "1  9.844730  1.243450e-14  19.039718  0.067797  0.680503  5.967181  91.318079   \n",
      "\n",
      "        DIS        RAD         TAX    PTRATIO           B      LSTAT  \n",
      "0  4.756868   4.471125  301.917933  17.837386  386.447872   9.468298  \n",
      "1  2.007242  18.988701  605.858757  19.604520  301.331695  18.572768  \n"
     ]
    }
   ],
   "source": [
    "# Calculate cluster characteristics\n",
    "best_kmeans = KMeans(n_clusters=best_k, random_state=42).fit(scaled_data)\n",
    "\n",
    "# Method 1: Calculate cluster means from original data\n",
    "cluster_means = df.groupby(best_kmeans.labels_).mean()\n",
    "\n",
    "# Method 2: Inverse transform centroids to original scale (equivalent to method 1)\n",
    "centroids_original = scaler.inverse_transform(best_kmeans.cluster_centers_)\n",
    "\n",
    "print(\"\\nMethod 1: Cluster means from original data:\")\n",
    "print(cluster_means)\n",
    "print(\"\\nMethod 2: Inverse-transformed centroids:\")\n",
    "print(pd.DataFrame(centroids_original, columns=df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e280fb",
   "metadata": {},
   "source": [
    "## Result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5161f47",
   "metadata": {},
   "source": [
    "The optimal k value is 2.\n",
    "\n",
    "From the above results, we can see that the group means are exactly consistent with the inverse normalized centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0a38aa",
   "metadata": {},
   "source": [
    "# Problem 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a52f8cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import homogeneity_score, completeness_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c897b7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the wine dataset\n",
    "wine = load_wine()\n",
    "df = pd.DataFrame(data=wine.data, columns=wine.feature_names)\n",
    "true_labels = wine.target\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c1f86bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform K-Means clustering with k=3\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "cluster_labels = kmeans.fit_predict(scaled_data)\n",
    "\n",
    "# Calculate Homogeneity and Completeness\n",
    "homogeneity = homogeneity_score(true_labels, cluster_labels)\n",
    "completeness = completeness_score(true_labels, cluster_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1ae35b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homogeneity Score: 0.8788\n",
      "Completeness Score: 0.8730\n"
     ]
    }
   ],
   "source": [
    "print(f\"Homogeneity Score: {homogeneity:.4f}\")\n",
    "print(f\"Completeness Score: {completeness:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5083bc58",
   "metadata": {},
   "source": [
    "## Result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c17196",
   "metadata": {},
   "source": [
    "Homogeneity Score (0.8788) :\n",
    "\n",
    "- Meaning: This score measures whether each cluster contains only data points from a single true category. A score of 0.8788 (close to 1) indicates high cluster purity, meaning most data points within each cluster belong to the same true category.\n",
    "- Information Provided: Homogeneity tells us about the purity of clusters. A high value indicates that the K-Means algorithm successfully grouped data points such that the mixing of different true categories within each cluster is minimized. In this case, about 87.88% of the clustering structure aligns with the true category boundaries in terms of purity.\n",
    "\n",
    "Completeness Score (0.8730):\n",
    "\n",
    "- Meaning: This score measures whether all data points from a given true category are assigned to the same cluster. A score of 0.8730 indicates that most data points from each true category are grouped into a single cluster.\n",
    "- Information Provided: Completeness reflects the extent to which clustering captures the entirety of each true category. A high value indicates the algorithm avoids splitting a true category across multiple clusters. Here, about 87.30% of the true category structure is preserved in the clustering."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
